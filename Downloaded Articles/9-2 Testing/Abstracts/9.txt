Abstract
We introduce Codex, a GPT language model ﬁne-
tuned on publicly available code from GitHub,
and study its Python code-writing capabilities.
A distinct production version of Codex powers
GitHub Copilot. On HumanEval, a new evalua-
tion set we release to measure functional correct-
ness for synthesizing programs from docstrings,
our model solves 28.8% of the problems, while
GPT-3 solves 0% and GPT-J solves 11.4%. Fur-
thermore, we ﬁnd that repeated sampling from the
model is a surprisingly effective strategy for pro-
ducing working solutions to difﬁcult prompts. Us-
ing this method, we solve 70.2% of our problems
with 100 samples per problem. Careful investiga-
tion of our model reveals its limitations, including
difﬁculty with docstrings describing long chains
of operations and with binding operations to vari-
ables. Finally, we discuss the potential broader
impacts of deploying powerful code generation
technologies, covering safety, security, and eco-
nomics.
*Equal contribution
1OpenAI, San Francisco, California, USA.
2Anthropic AI, San Francisco, California, USA. Work per-
formed while at OpenAI.
3Zipline, South San Francisco, California, USA. Work per-
formed while at OpenAI.
Correspondence to:
Mark Chen <mark@openai.com>,
Jerry
Tworek
<jt@openai.com>,
Heewoo
Jun
<hee-
woo@openai.com>, Qiming Yuan <qiming@openai.com>.
1.