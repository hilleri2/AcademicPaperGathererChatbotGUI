abstracts that humans struggle to differ-
entiate from those written by human researchers54. Nonetheless,
using LLMs for scientiﬁc writing currently requires signiﬁcant
revisions by human authors due to inaccurate, shallow and
repetitive outputs (Supplementary Data, example 6). It is antici-
pated that LLMs will impact the communication of scientiﬁc
ﬁndings9,55. However, their use may compromise the quality of
scientiﬁc publications by complicating the veriﬁcation of the
authenticity of scientiﬁc text, as well as underlying facts and
references. To make scientiﬁc developments as transparent as
possible, it will be important to deﬁne a framework for the usage
of LLMs in the scientiﬁc context9,46,56.
Computer programming. Besides written language, LLMs can
also be trained on code in various programming languages.
Popular applications of LLMs in the ﬁelds of data science and
bioinformatics are code debugging and simpliﬁcation, translation
to different programming languages, and derivation of code from
natural language input (Supplementary Data, example 7). While
these outputs can sometimes be inaccurate, LLMs are able to
provide solutions upon further request and can help researchers
with simple and complex coding tasks, e.g., fast visualization of
data. This provides scientists with a technical skillset, enabling
clinicians and others who lack substantial programming expertise
to use code-based tools to test their hypotheses and boost their
efﬁciency.
Reproducibility. Reproducibility is a fundamental prerequisite
for maintaining high standards in scientiﬁc practice. Although
dynamically updating models can lead to improved performance
compared to their predecessors5,21, such updates, or restrictions
to their access, can also compromise reliable and consistent
reproduction of research ﬁndings. For instance, we observed
substantial differences between the initial prompted queries using
GPT-3.5 and re-prompting with GPT-4 (Box 2, Supplementary
Data). Minor changes were also seen when using different ver-
sions of GPT-3.5. This highlights the importance of meticulous
documentation of prompts and model versions in scientiﬁc
publications, as well as the implementation of open-access ver-
sion control solutions by developers, to enable the future re-
creation of version-speciﬁc content.
Medical education
Education has changed as new technologies have emerged. For
example, the availability of calculators enabled mathematics
teaching to concentrate on theories and arguments rather than
learning how to undertake complex mental calculations. Because
a vast amount of knowledge is now readily available via the
internet and smart devices, memorization has become less of a
requisite in medical education57,58. Instead, educators have placed
more emphasis on critical thinking, debating and discussing, as
these are skills that are still required. LLMs will likely introduce
further changes to educational methods, as they can assist with
reasoning. In the following section, we will explore the potential
of LLMs in medical education, examining their potential impact
on the critical thinking abilities of healthcare professionals and
COMMUNICATIONS MEDICINE | https://doi.org/10.1038/s43856-023-00370-1
PERSPECTIVE
COMMUNICATIONS MEDICINE |  (2023) 3:141 | https://doi.org/10.1038/s43856-023-00370-1 | www.nature.com/commsmed
5

identifying important topics that should be addressed in medical
education as LLMs become more prevalent.
Beneﬁcial uses of LLMs in education. When used responsibly,
LLMs can complement educational strategies in many ways.
They can provide convincing summaries, presentations, trans-
lations, explanations, step-by-step guides and contextualization
on many topics, coupled with customizable depth, tone and
style of the output. For example, they can break down complex
concepts to an amateur level (Box 2, Supplementary Data,
example 8, 9) and provide individualized feedback on academic
topics with reasonable explanations (Supplementary Data,
example 9)6. These properties make LLMs suitable to function
as personalized teaching assistants that could, for example,
prepare revision aids and examples of tests. LLMs can be used
to create interactive and engaging learning simulations. For
example, students may use LLMs to simulate conversations
with ﬁctitious patients, allowing them to practice taking patient
histories or assessing diagnosis and treatment plans (Supple-
mentary Data, example 11).
Impact on critical thinking. The use of LLMs as educational
tools raises concerns, as students can use them in inappropriate
ways. As for scientiﬁc settings, usage of LLMs at educational
institutions will need to be transparently regulated, for example,
with the help of machine learning algorithms to differentiate
between text generated by LLMs and self-written text59. Still, it is
to be expected that LLMs could negatively impact students’
abilities to discriminate valuable information from wrong and
irrelevant input. This can only be achieved via critical thinking,
which is based on understanding, analytical thinking and critical
evaluation60,61. Therefore, the use of LLMs as a crutch for
assignments could lead to a decrease in the critical thinking and
creativity of students. In the context of medical education, in
addition to externalizing factual knowledge, readily available
LLMs harbor the danger of externalization of medical reasoning.
Education about LLMs. It will be essential to implement
responsible interaction guidelines for LLM use to prevent inap-
propriate use by students, especially in medical education, where
misinformation can lead to inaccurate decisions, potentially
resulting in patient harm. All students should undergo a basic